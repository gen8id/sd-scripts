"""
BLIP + WD14 í•˜ì´ë¸Œë¦¬ë“œ ìº¡ì…˜ ìƒì„±ê¸° (ìˆ˜ì • ë²„ì „)
ì‹¤ì‚¬ LoRA í•™ìŠµì„ ìœ„í•œ í†µí•© ìº¡ì…˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

í•„ìš” í™˜ê²½: kohya_ss (sd-scripts)
"""

import os
import sys
import traceback
from pathlib import Path
from tqdm import tqdm
import numpy as np
from PIL import Image
import torch
import logging
import argparse
import nltk
from nltk.stem import WordNetLemmatizer

# sd-scripts ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
nltk_models_dir = os.path.join(os.path.dirname(__file__), "..", "models", "nltk_data")
os.makedirs(nltk_models_dir, exist_ok=True)

# NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ
try:
    nltk.data.path.append(nltk_models_dir)
    nltk.download('wordnet', download_dir=nltk_models_dir, quiet=True)
    nltk.download('omw-1.4', download_dir=nltk_models_dir, quiet=True)
    lemmatizer = WordNetLemmatizer()
except Exception as e:
    print(f"âš ï¸ NLTK ì´ˆê¸°í™” ê²½ê³ : {e}")
    lemmatizer = None


# Kohya_ss ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from finetune.wd14_tagger_gen8id import preprocess_image, run_batch
except ImportError:
    print("âŒ Kohya_ss í™˜ê²½ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”!")
    print("ê²½ë¡œ: sd-scripts/ í´ë” ì•ˆì—ì„œ ì‹¤í–‰")
    traceback.print_exc()
    sys.exit(1)


# ==============================
# âš™ï¸ ì„¤ì • (ìˆ˜ì • ê°€ëŠ¥)
# ==============================

class Config:
    # ë°ì´í„°ì…‹ ê²½ë¡œ
    DATASET_DIRS = [
        "../dataset/mainchar",
        "../dataset/bg",
    ]
    
    # ëª¨ë¸ ì„¤ì •
    BLIP_MODEL_PATH = "Salesforce/blip-image-captioning-large"
    BLIP_CACHE_DIR = "../models/blip-image-captioning-large"
    WD14_MODEL_PATH = "SmilingWolf/wd-v1-4-moat-tagger-v2"
    WD14_CACHE_DIR = "../models/wd-v1-4-moat-tagger-v2"

    # WD14 ì„ê³„ê°’
    WD14_GENERAL_THRESHOLD = 0.35
    WD14_CHARACTER_THRESHOLD = 0.85
    
    # BLIP ì„¤ì •
    BLIP_MAX_LENGTH = 75
    BLIP_NUM_BEAMS = 1
    
    # ì œê±°í•  WD14 ë©”íƒ€ íƒœê·¸
    REMOVE_TAGS = [
        "1girl", "1boy", "solo", "looking at viewer",
        "simple background", "white background", "grey background",
        "highres", "absurdres", "lowres", "bad anatomy",
        "signature", "watermark", "artist name", "dated",
        "rating:safe", "rating:questionable", "rating:explicit",
    ]
    
    # ì¶œë ¥ ì„¤ì •
    OUTPUT_ENCODING = "utf-8"
    OVERWRITE_EXISTING = True
    CREATE_BACKUP = True
    
    # ë””ë°”ì´ìŠ¤
    DEVICE = "cuda"
    
    # ìºë¦­í„° í”„ë¦¬í”½ìŠ¤ (CLIì—ì„œ ì„¤ì •)
    CHARACTER_PREFIX = ""


# ==============================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================

def lemmatize_tags(tags_list):
    """íƒœê·¸ë¥¼ ê¸°ë³¸í˜•ìœ¼ë¡œ ë³€í™˜"""
    if lemmatizer is None:
        return tags_list
    return [lemmatizer.lemmatize(tag.lower()) for tag in tags_list]


def normalize_tags(tags_str):
    """íƒœê·¸ ì •ê·œí™”: ì†Œë¬¸ì ë³€í™˜, ê³µë°± ì •ë¦¬, ì¤‘ë³µ ì œê±°"""
    if not tags_str:
        return []
    tags = [tag.strip().lower() for tag in tags_str.split(',')]
    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    seen = set()
    unique_tags = []
    for tag in tags:
        if tag and tag not in seen:
            seen.add(tag)
            unique_tags.append(tag)
    return unique_tags


def remove_unwanted_tags(tags_list, remove_list):
    """ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°"""
    remove_set = set(tag.lower() for tag in remove_list)
    return [tag for tag in tags_list if tag not in remove_set]


def merge_captions(blip_caption, wd14_tags, remove_tags):
    """
    BLIP ìº¡ì…˜ê³¼ WD14 íƒœê·¸ ë³‘í•©
    
    í˜•ì‹: [BLIP ë¬¸ì¥], [WD14 íƒœê·¸ë“¤]
    """
    # BLIP ì •ê·œí™”
    blip_normalized = blip_caption.strip().lower() if blip_caption else ""
    
    # WD14 íƒœê·¸ ì •ê·œí™” ë° í•„í„°ë§
    wd14_normalized = normalize_tags(wd14_tags)
    wd14_lemmatized = lemmatize_tags(wd14_normalized)
    wd14_filtered = remove_unwanted_tags(wd14_lemmatized, remove_tags)
    
    # BLIP ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°ìš©)
    blip_words = set(blip_normalized.replace(',', ' ').split()) if blip_normalized else set()
    
    # WD14ì—ì„œ BLIPì— ì´ë¯¸ í¬í•¨ëœ ë‹¨ì–´ ì œê±°
    wd14_deduped = []
    for tag in wd14_filtered:
        # íƒœê·¸ê°€ BLIP ë¬¸ì¥ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
        if not any(word in tag or tag in word for word in blip_words):
            wd14_deduped.append(tag)
    
    # ìµœì¢… ë³‘í•©: BLIP (ë¬¸ì¥) + WD14 (íƒœê·¸)
    if blip_normalized and wd14_deduped:
        merged = f"{blip_normalized}, {', '.join(wd14_deduped)}"
    elif blip_normalized:
        merged = blip_normalized
    elif wd14_deduped:
        merged = ', '.join(wd14_deduped)
    else:
        merged = ""
    
    return merged


# ==============================
# ğŸ¨ ìº¡ì…˜ ìƒì„± í•¨ìˆ˜
# ==============================

def generate_blip_caption(image_path, model, processor, config):
    """BLIPìœ¼ë¡œ ìì—°ì–´ ìº¡ì…˜ ìƒì„±"""
    try:
        image = Image.open(image_path).convert("RGB")
        
        inputs = processor(image, return_tensors="pt").to(config.DEVICE)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=config.BLIP_MAX_LENGTH,
                num_beams=config.BLIP_NUM_BEAMS,
            )
        
        caption = processor.decode(outputs[0], skip_special_tokens=True)
        return caption.strip()
        
    except Exception as e:
        print(f"âš ï¸ BLIP ìƒì„± ì‹¤íŒ¨ ({image_path.name}): {e}")
        return ""


def generate_wd14_tags(image_path, tagger, config):
    """WD14ë¡œ íƒœê·¸ ìƒì„±"""
    try:
        # WD14Tagger.tag() ë©”ì„œë“œ í˜¸ì¶œ
        tags_str = tagger.tag(
            str(image_path),
            general_threshold=config.WD14_GENERAL_THRESHOLD,
            character_threshold=config.WD14_CHARACTER_THRESHOLD,
        )
        return tags_str if tags_str else ""
        
    except Exception as e:
        print(f"âš ï¸ WD14 ìƒì„± ì‹¤íŒ¨ ({image_path.name}): {e}")
        return ""


# ==============================
# ğŸ“ íŒŒì¼ ì²˜ë¦¬
# ==============================

def get_image_files(directory):
    """ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
    
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(directory).glob(f"*{ext}"))
        image_files.extend(Path(directory).glob(f"*{ext.upper()}"))
    
    return sorted(image_files)


def create_backup(caption_path):
    """ê¸°ì¡´ ìº¡ì…˜ íŒŒì¼ ë°±ì—…"""
    if caption_path.exists():
        backup_dir = caption_path.parent / "caption_backup"
        backup_dir.mkdir(exist_ok=True)
        
        backup_path = backup_dir / caption_path.name
        import shutil
        shutil.copy2(caption_path, backup_path)


# ==============================
# ğŸš€ ë©”ì¸ í”„ë¡œì„¸ìŠ¤
# ==============================

def process_directory(directory, blip_model, blip_processor, wd14_tagger, config):
    """ë‹¨ì¼ ë””ë ‰í† ë¦¬ ì²˜ë¦¬"""
    
    print(f"\nğŸ“ ì²˜ë¦¬ ì¤‘: {directory}")
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_files = get_image_files(directory)
    
    if not image_files:
        print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory}")
        return 0
    
    print(f"ğŸ“¸ {len(image_files)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
    
    success_count = 0
    skip_count = 0
    
    for image_path in tqdm(image_files, desc="ìº¡ì…˜ ìƒì„±"):
        
        # ìº¡ì…˜ íŒŒì¼ ê²½ë¡œ
        caption_path = image_path.with_suffix('.txt')
        
        # ê¸°ì¡´ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if caption_path.exists() and not config.OVERWRITE_EXISTING:
            skip_count += 1
            continue
        
        # ë°±ì—… ìƒì„±
        if config.CREATE_BACKUP and caption_path.exists():
            create_backup(caption_path)
        
        try:
            # 1. BLIP ìº¡ì…˜ ìƒì„±
            blip_caption = generate_blip_caption(
                image_path, blip_model, blip_processor, config
            )
            
            # 2. WD14 íƒœê·¸ ìƒì„±
            wd14_tags = generate_wd14_tags(image_path, wd14_tagger, config)
            
            # 3. ë³‘í•©
            merged_caption = merge_captions(
                blip_caption, wd14_tags, config.REMOVE_TAGS
            )
            
            # 4. ìºë¦­í„°ëª… prefix ì¶”ê°€
            if config.CHARACTER_PREFIX:
                char_token = config.CHARACTER_PREFIX.strip()
                merged_caption = f"{char_token}, {merged_caption}"
            
            # 5. ì €ì¥
            if merged_caption:
                with open(caption_path, 'w', encoding=config.OUTPUT_ENCODING) as f:
                    f.write(merged_caption)
                success_count += 1
            else:
                print(f"âš ï¸ ë¹ˆ ìº¡ì…˜: {image_path.name}")
            
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨ ({image_path.name}): {e}")
            traceback.print_exc()
            continue
    
    print(f"âœ… ì™„ë£Œ: {success_count}ê°œ ìƒì„±, {skip_count}ê°œ ìŠ¤í‚µ")
    return success_count


# ==============================
# ğŸ·ï¸ WD14 Tagger í´ë˜ìŠ¤
# ==============================

class WD14Tagger:
    def __init__(
        self,
        config,
        model_dir=None,
        repo_id=None,
        onnx=True,
        general_threshold=0.35,
        character_threshold=0.85,
        device=None,
    ):
        self.config = config
        self.model_dir = model_dir or config.WD14_CACHE_DIR
        self.repo_id = repo_id or config.WD14_MODEL_PATH
        self.onnx = onnx
        self.general_threshold = general_threshold
        self.character_threshold = character_threshold
        self.device = device
        
        # âœ… tag_freq ì´ˆê¸°í™”
        self.tag_freq = {}
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._init_model()

    def _init_model(self):
        """ëª¨ë¸ ë¡œë”© ë° ë ˆì´ë¸” CSV ì²˜ë¦¬"""
        from huggingface_hub import hf_hub_download

        model_location = os.path.join(self.model_dir, self.repo_id.replace("/", "_"))
        os.makedirs(model_location, exist_ok=True)

        # ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        if self.onnx:
            import onnx
            import onnxruntime as ort

            onnx_path = os.path.join(model_location, "model.onnx")
            if not os.path.exists(onnx_path):
                print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/model.onnx")
                hf_hub_download(
                    repo_id=self.repo_id, 
                    filename="model.onnx", 
                    local_dir=model_location
                )

            model = onnx.load(onnx_path)
            self.input_name = model.graph.input[0].name
            del model

            # Provider ì„¤ì •
            providers = ["CPUExecutionProvider"]
            available_providers = ort.get_available_providers()
            if "CUDAExecutionProvider" in available_providers:
                providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
            elif "ROCMExecutionProvider" in available_providers:
                providers = ["ROCMExecutionProvider", "CPUExecutionProvider"]

            self.ort_sess = ort.InferenceSession(onnx_path, providers=providers)

        # CSV ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        csv_file = os.path.join(model_location, "selected_tags.csv")
        if not os.path.exists(csv_file):
            print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/selected_tags.csv")
            hf_hub_download(
                repo_id=self.repo_id,
                filename="selected_tags.csv",
                local_dir=model_location
            )

        import csv
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            lines = list(reader)
        
        header, rows = lines[0], lines[1:]
        assert header[0] == "tag_id" and header[1] == "name" and header[2] == "category"

        self.rating_tags = [row[1] for row in rows if row[2] == "9"]
        self.general_tags = [row[1] for row in rows if row[2] == "0"]
        self.character_tags = [row[1] for row in rows if row[2] == "4"]

    def tag(self, image_path, general_threshold=None, character_threshold=None):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ íƒœê¹… - íƒœê·¸ ë¬¸ìì—´ ë°˜í™˜
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            img = Image.open(image_path).convert("RGB")
            img_array = preprocess_image(img)
            img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            
            # ì¶”ë¡ 
            preds = self.ort_sess.run(None, {self.input_name: img_array})[0]
            
            # Threshold ì„¤ì •
            gen_thresh = general_threshold if general_threshold is not None else self.general_threshold
            char_thresh = character_threshold if character_threshold is not None else self.character_threshold
            
            # íƒœê·¸ ì¶”ì¶œ
            tags = []
            
            # Character íƒœê·¸ ë¨¼ì € (ìˆìœ¼ë©´)
            for i, tag in enumerate(self.character_tags):
                if preds[0][i] >= char_thresh:
                    tags.append(tag.replace('_', ' '))
            
            # General íƒœê·¸
            for i, tag in enumerate(self.general_tags):
                if preds[0][len(self.character_tags) + i] >= gen_thresh:
                    tags.append(tag.replace('_', ' '))
            
            return ', '.join(tags)
            
        except Exception as e:
            print(f"âš ï¸ WD14 íƒœê¹… ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return ""


# ==============================
# ğŸ¯ ë©”ì¸ í•¨ìˆ˜
# ==============================

def main():
    parser = argparse.ArgumentParser(description="BLIP + WD14 í•˜ì´ë¸Œë¦¬ë“œ ìº¡ì…˜ ìƒì„±")
    parser.add_argument(
        "--dirs", 
        nargs="+", 
        help="ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ ëª©ë¡ (ê¸°ë³¸: configì—ì„œ ì„¤ì •)"
    )
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="ê¸°ì¡´ ìº¡ì…˜ ë®ì–´ì“°ê¸°"
    )
    parser.add_argument(
        "--device",
        default="cuda",
        help="ë””ë°”ì´ìŠ¤ (cuda/cpu)"
    )
    parser.add_argument(
        "--char",
        type=str,
        default="",
        help="ëª¨ë“  ìº¡ì…˜ ì•ì— ë¶™ì¼ ìºë¦­í„°ëª… (ì˜ˆ: 'sakura_char')"
    )

    args = parser.parse_args()
    
    # Config ì„¤ì •
    config = Config()
    if args.dirs:
        config.DATASET_DIRS = args.dirs
    config.OVERWRITE_EXISTING = args.overwrite
    config.CHARACTER_PREFIX = args.char
    config.DEVICE = args.device
    
    print("=" * 60)
    print("ğŸ¨ BLIP + WD14 í•˜ì´ë¸Œë¦¬ë“œ ìº¡ì…˜ ìƒì„±ê¸°")
    print("=" * 60)
    print(f"ğŸ“ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {config.DATASET_DIRS}")
    print(f"ğŸ’¾ ë®ì–´ì“°ê¸°: {config.OVERWRITE_EXISTING}")
    print(f"ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {config.DEVICE}")
    if config.CHARACTER_PREFIX:
        print(f"ğŸ·ï¸  ìºë¦­í„° í”„ë¦¬í”½ìŠ¤: '{config.CHARACTER_PREFIX}'")
    print("=" * 60)
    
    # ëª¨ë¸ ë¡œë“œ
    print("\nğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    try:
        # BLIP ë¡œë“œ
        from transformers import BlipProcessor, BlipForConditionalGeneration
        
        print("  â†’ BLIP ëª¨ë¸ ë¡œë”©...")
        blip_processor = BlipProcessor.from_pretrained(
            config.BLIP_MODEL_PATH, 
            cache_dir=config.BLIP_CACHE_DIR
        )
        blip_model = BlipForConditionalGeneration.from_pretrained(
            config.BLIP_MODEL_PATH,
            cache_dir=config.BLIP_CACHE_DIR
        ).to(config.DEVICE)
        blip_model.eval()
        
        # WD14 ë¡œë“œ
        print("  â†’ WD14 Tagger ë¡œë”©...")
        wd14_tagger = WD14Tagger(
            config=config,
            model_dir=config.WD14_CACHE_DIR,
            general_threshold=config.WD14_GENERAL_THRESHOLD,
            character_threshold=config.WD14_CHARACTER_THRESHOLD,
        )
        
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        sys.exit(1)
    
    # ê° ë””ë ‰í† ë¦¬ ì²˜ë¦¬
    total_success = 0
    
    for directory in config.DATASET_DIRS:
        dir_path = Path(directory)
        if not dir_path.exists():
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {directory}")
            continue
        
        count = process_directory(
            directory, blip_model, blip_processor, wd14_tagger, config
        )
        total_success += count
    
    # ì™„ë£Œ ë©”ì‹œì§€
    print("\n" + "=" * 60)
    print(f"ğŸ‰ ì „ì²´ ì™„ë£Œ!")
    print(f"âœ… ì´ {total_success}ê°œ ìº¡ì…˜ ìƒì„±ë¨")
    print("=" * 60)
    
    # ê²°ê³¼ ì˜ˆì‹œ ì¶œë ¥
    print("\nğŸ“ ìƒì„± ì˜ˆì‹œ:")
    for directory in config.DATASET_DIRS:
        txt_files = list(Path(directory).glob("*.txt"))
        if txt_files:
            example_file = txt_files[0]
            with open(example_file, 'r', encoding='utf-8') as f:
                content = f.read()
            print(f"\n{example_file.name}:")
            print(f"  {content}")
            break


if __name__ == "__main__":
    main()