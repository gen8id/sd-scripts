"""
BLIP + WD14 í•˜ì´ë¸Œë¦¬ë“œ ìº¡ì…˜ ìƒì„±ê¸° (ìˆ˜ì • ë²„ì „)
ì‹¤ì‚¬ LoRA í•™ìŠµì„ ìœ„í•œ í†µí•© ìº¡ì…˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

í•„ìš” í™˜ê²½: kohya_ss (sd-scripts)
"""
import argparse
import os
import sys
import traceback
from pathlib import Path
import nltk
import numpy as np
import torch
from PIL import Image
from nltk.stem import WordNetLemmatizer
import onnx
import re
import onnxruntime as ort
from wd14_tagger_gen8id import preprocess_image, run_batch
from transformers import BlipProcessor, BlipForConditionalGeneration
import requests
import gzip
import json


# ==============================
# âš™ï¸ ì„¤ì • (ìˆ˜ì • ê°€ëŠ¥)
# ==============================
class Config:

    # ë°ì´í„°ì…‹ ê²½ë¡œ
    DATASET_DIRS = [
        "../dataset/train/mainchar",
        "../dataset/train/background",
    ]
    WATCH_DIR = "../dataset/captioning/mainchar"
    
    # ëª¨ë¸ ì„¤ì •
    BLIP_MODEL_PATH = "Salesforce/blip-image-captioning-large"
    BLIP_CACHE_DIR = "../models/blip-image-captioning-large"
    WD14_MODEL_PATH = "SmilingWolf/wd-v1-4-moat-tagger-v2"
    WD14_CACHE_DIR = "../models/wd-v1-4-moat-tagger-v2"

    # WD14 ì„ê³„ê°’
    WD14_GENERAL_THRESHOLD = 0.35
    WD14_CHARACTER_THRESHOLD = 0.85
    
    # BLIP ì„¤ì •
    BLIP_MAX_LENGTH = 75
    BLIP_NUM_BEAMS = 1
    
    # ì œê±°í•  WD14 ë©”íƒ€ íƒœê·¸
    REMOVE_TAGS = [
        "1girl", "1boy", "solo", "looking at viewer",
        "simple background", "white background", "grey background",
        "highres", "absurdres", "lowres", "bad anatomy",
        "signature", "watermark", "artist name", "dated",
        "yuki miku", "snivy", "winter uniform", ":d"
        "rating:safe", "rating:questionable", "rating:explicit",
    ]
    
    # ì¶œë ¥ ì„¤ì •
    OUTPUT_ENCODING = "utf-8"
    OVERWRITE_EXISTING = True
    CREATE_BACKUP = True
    
    # ë””ë°”ì´ìŠ¤
    DEVICE = "cuda"
    
    # ìºë¦­í„° í”„ë¦¬í”½ìŠ¤ (CLIì—ì„œ ì„¤ì •)
    CHARACTER_PREFIX = ""


# ==============================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==============================
def download_character_tags():
    """Danbooru íƒœê·¸ ë°ì´í„°ë² ì´ìŠ¤ ë‹¤ìš´ë¡œë“œ"""
    url = "https://danbooru.donmai.us/tags.json"

    characters = set()
    page = 1

    print("Downloading character tags from Danbooru...")

    while True:
        try:
            response = requests.get(
                url,
                params={
                    'search[category]': 4,  # 4 = character
                    'limit': 1000,
                    'page': page
                },
                timeout=10
            )

            if not response.ok:
                break

            data = response.json()
            if not data:
                break

            for tag in data:
                characters.add(tag['name'].lower())

            print(f"Page {page}: {len(characters)} characters")
            page += 1

            # API rate limit ê³ ë ¤
            import time
            time.sleep(1)

        except Exception as e:
            print(f"Error: {e}")
            break

    # ì €ì¥
    with open('danbooru_characters.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(sorted(characters)))

    print(f"Total characters saved: {len(characters)}")
    return characters

def lemmatize_tags(tags_list):
    """íƒœê·¸ë¥¼ ê¸°ë³¸í˜•ìœ¼ë¡œ ë³€í™˜"""
    if lemmatizer is None:
        return tags_list
    return [lemmatizer.lemmatize(tag.lower()) for tag in tags_list]


def normalize_tags(tags_str):
    """íƒœê·¸ ì •ê·œí™”: ê³ ìœ ëª…ì‚¬ ì œê±°, ì†Œë¬¸ì ë³€í™˜, ê³µë°± ì •ë¦¬, ì¤‘ë³µ ì œê±°"""
    if not tags_str:
        return []

    # ìºë¦­í„°ëª… íŒ¨í„´ (ê´„í˜¸ í¬í•¨/ë¯¸í¬í•¨)
    character_patterns = [
        r'^[a-z]+ [a-z]+\s*\([^)]+\)$',  # "ganyu (genshin impact)"
        r'^[a-z]+ [a-z]+ [a-z]+$',        # "artoria pendragon fate" (3ë‹¨ì–´)
    ]

    # ë¨¼ì € stripë§Œ í•˜ê³  ì›ë³¸ ì¼€ì´ìŠ¤ ìœ ì§€
    tags = [tag.strip().lower() for tag in tags_str.split(',')]
    seen = set()
    unique_tags = []

    for tag in tags:
        if not tag:
            continue
        # ìºë¦­í„°ëª… íŒ¨í„´ ì œê±°
        is_character = any(re.match(pattern, tag) for pattern in character_patterns)
        if is_character:
            print(f"Removed character name: {tag}")
            continue
        if tag not in seen:
            seen.add(tag)
            unique_tags.append(tag)

    return unique_tags


def remove_unwanted_tags(tags_list, remove_list):
    """ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°"""
    remove_set = set(tag.lower() for tag in remove_list)
    return [tag for tag in tags_list if tag not in remove_set]


def merge_captions(blip_caption, wd14_tags):
    """
    BLIP ìº¡ì…˜ê³¼ WD14 íƒœê·¸ ë³‘í•©
    í˜•ì‹: [BLIP ë¬¸ì¥], [WD14 íƒœê·¸ë“¤]
    """
    config = Config()
    # BLIP ì •ê·œí™”
    blip_normalized = blip_caption.strip().lower() if blip_caption else ""
    
    # WD14 íƒœê·¸ ì •ê·œí™” ë° í•„í„°ë§
    wd14_normalized = normalize_tags(wd14_tags)
    wd14_lemmatized = lemmatize_tags(wd14_normalized)
    wd14_filtered = remove_unwanted_tags(wd14_lemmatized, config.REMOVE_TAGS)
    
    # BLIP ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°ìš©)
    blip_words = set(blip_normalized.replace(',', ' ').split()) if blip_normalized else set()
    
    # WD14ì—ì„œ BLIPì— ì´ë¯¸ í¬í•¨ëœ ë‹¨ì–´ ì œê±°
    wd14_deduped = []
    for tag in wd14_filtered:
        # íƒœê·¸ê°€ BLIP ë¬¸ì¥ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
        if not any(word in tag or tag in word for word in blip_words):
            wd14_deduped.append(tag)
    
    # ìµœì¢… ë³‘í•©: BLIP (ë¬¸ì¥) + WD14 (íƒœê·¸)
    if blip_normalized and wd14_deduped:
        merged = f"{blip_normalized}, {', '.join(wd14_deduped)}"
    elif blip_normalized:
        merged = blip_normalized
    elif wd14_deduped:
        merged = ', '.join(wd14_deduped)
    else:
        merged = ""
    
    return merged


# ==============================
# ğŸ¨ ìº¡ì…˜ ìƒì„± í•¨ìˆ˜
# ==============================

def generate_blip_caption(image_path):
    """BLIPìœ¼ë¡œ ìì—°ì–´ ìº¡ì…˜ ìƒì„±"""
    config = Config()
    try:

        image = Image.open(image_path).convert("RGB")
        inputs = blip_processor(image, return_tensors="pt").to(config.DEVICE)
        
        with torch.no_grad():
            outputs = blip_model.generate(
                **inputs,
                max_length=config.BLIP_MAX_LENGTH,
                num_beams=config.BLIP_NUM_BEAMS,
            )
        
        caption = blip_processor.decode(outputs[0], skip_special_tokens=True)
        return caption.strip()
        
    except Exception as e:
        print(f"âš ï¸ BLIP ìƒì„± ì‹¤íŒ¨ ({image_path.name}): {e}")
        return ""


def generate_wd14_tags(image_path):
    """WD14ë¡œ íƒœê·¸ ìƒì„±"""
    config = Config()
    try:
        # WD14Tagger.tag() ë©”ì„œë“œ í˜¸ì¶œ
        tags_str = wd14_tagger.tag(
            str(image_path),
            general_threshold=config.WD14_GENERAL_THRESHOLD,
            character_threshold=config.WD14_CHARACTER_THRESHOLD,
        )
        return tags_str if tags_str else ""
        
    except Exception as e:
        print(f"âš ï¸ WD14 ìƒì„± ì‹¤íŒ¨ ({image_path.name}): {e}")
        return ""


# ==============================
# ğŸ“ íŒŒì¼ ì²˜ë¦¬
# ==============================

def get_image_files(directory):
    """ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
    
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(directory).glob(f"*{ext}"))
        image_files.extend(Path(directory).glob(f"*{ext.upper()}"))
    
    return sorted(image_files)


def create_backup(caption_path):
    """ê¸°ì¡´ ìº¡ì…˜ íŒŒì¼ ë°±ì—…"""
    if caption_path.exists():
        backup_dir = caption_path.parent / "caption_backup"
        backup_dir.mkdir(exist_ok=True)
        backup_path = backup_dir / caption_path.name
        import shutil
        shutil.copy2(caption_path, backup_path)


# ==============================
# ğŸ·ï¸ WD14 Tagger í´ë˜ìŠ¤
# ==============================

class WD14Tagger:

    def __init__(
        self,
        config,
        model_dir=None,
        repo_id=None,
        onnx=True,
        general_threshold=0.35,
        character_threshold=0.85,
        device=None,
    ):
        self.config = config
        self.model_dir = model_dir or config.WD14_CACHE_DIR
        self.repo_id = repo_id or config.WD14_MODEL_PATH
        self.onnx = onnx
        self.general_threshold = general_threshold
        self.character_threshold = character_threshold
        self.device = device
        
        # âœ… tag_freq ì´ˆê¸°í™”
        self.tag_freq = {}
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._init_model()

    def _init_model(self):
        """ëª¨ë¸ ë¡œë”© ë° ë ˆì´ë¸” CSV ì²˜ë¦¬"""
        from huggingface_hub import hf_hub_download

        model_location = os.path.join(self.model_dir, self.repo_id.replace("/", "_"))
        os.makedirs(model_location, exist_ok=True)

        # ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        if self.onnx:
            import onnx
            import onnxruntime as ort

            onnx_path = os.path.join(model_location, "model.onnx")
            if not os.path.exists(onnx_path):
                print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/model.onnx")
                hf_hub_download(
                    repo_id=self.repo_id, 
                    filename="model.onnx", 
                    local_dir=model_location
                )

            onnx_model = onnx.load(onnx_path)
            self.input_name = onnx_model.graph.input[0].name
            del onnx_model

            # Provider ì„¤ì •
            providers = ["CPUExecutionProvider"]
            available_providers = ort.get_available_providers()
            if "CUDAExecutionProvider" in available_providers:
                providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
            elif "ROCMExecutionProvider" in available_providers:
                providers = ["ROCMExecutionProvider", "CPUExecutionProvider"]

            self.ort_sess = ort.InferenceSession(onnx_path, providers=providers)

        # CSV ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        csv_file = os.path.join(model_location, "selected_tags.csv")
        if not os.path.exists(csv_file):
            print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/selected_tags.csv")
            hf_hub_download(
                repo_id=self.repo_id,
                filename="selected_tags.csv",
                local_dir=model_location
            )

        import csv
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            lines = list(reader)
        
        header, rows = lines[0], lines[1:]
        assert header[0] == "tag_id" and header[1] == "name" and header[2] == "category"

        self.rating_tags = [row[1] for row in rows if row[2] == "9"]
        self.general_tags = [row[1] for row in rows if row[2] == "0"]
        self.character_tags = [row[1] for row in rows if row[2] == "4"]

    def tag(self, image_path, general_threshold=None, character_threshold=None):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ íƒœê¹… - íƒœê·¸ ë¬¸ìì—´ ë°˜í™˜
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            img = Image.open(image_path).convert("RGB")
            img_array = preprocess_image(img)
            img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            
            # ì¶”ë¡ 
            preds = self.ort_sess.run(None, {self.input_name: img_array})[0]
            
            # Threshold ì„¤ì •
            gen_thresh = general_threshold if general_threshold is not None else self.general_threshold
            char_thresh = character_threshold if character_threshold is not None else self.character_threshold
            
            # íƒœê·¸ ì¶”ì¶œ
            tags = []
            
            # Character íƒœê·¸ ë¨¼ì € (ìˆìœ¼ë©´)
            for i, tag in enumerate(self.character_tags):
                if preds[0][i] >= char_thresh:
                    tags.append(tag.replace('_', ' '))
            
            # General íƒœê·¸
            for i, tag in enumerate(self.general_tags):
                if preds[0][len(self.character_tags) + i] >= gen_thresh:
                    tags.append(tag.replace('_', ' '))
            
            return ', '.join(tags)
            
        except Exception as e:
            print(f"âš ï¸ WD14 íƒœê¹… ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return ""


def load_models(config):

    try:


        print("  â†’ NLTK ëª¨ë¸ ë¡œë”©...")
        # sd-scripts ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
        nltk_models_dir = os.path.join(os.path.dirname(__file__), "..", "models", "nltk_data")
        os.makedirs(nltk_models_dir, exist_ok=True)

        # NLTK ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        nltk.data.path.append(nltk_models_dir)
        nltk.download('wordnet', download_dir=nltk_models_dir, quiet=True)
        nltk.download('omw-1.4', download_dir=nltk_models_dir, quiet=True)
        
        global characters
        global lemmatizer
        global blip_processor
        global blip_model
        global wd14_tagger

        lemmatizer = WordNetLemmatizer()
        # BLIP ë¡œë“œ
        print("  â†’ BLIP ëª¨ë¸ ë¡œë”©...")
        blip_processor = BlipProcessor.from_pretrained(
            config.BLIP_MODEL_PATH,
            cache_dir=config.BLIP_CACHE_DIR
        )
        
        blip_model = BlipForConditionalGeneration.from_pretrained(
            config.BLIP_MODEL_PATH,
            cache_dir=config.BLIP_CACHE_DIR
        ).to(config.DEVICE)
        blip_model.eval()

        # WD14 ë¡œë“œ
        print("  â†’ WD14 Tagger ë¡œë”©...")
        wd14_tagger = WD14Tagger(
            config=config,
            model_dir=config.WD14_CACHE_DIR,
            general_threshold=config.WD14_GENERAL_THRESHOLD,
            character_threshold=config.WD14_CHARACTER_THRESHOLD,
        )

        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n")

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        sys.exit(1)


def generate_caption(image_path):

    config = Config()
    # ìº¡ì…˜ íŒŒì¼ ê²½ë¡œ
    caption_path = image_path.with_suffix('.txt')

    # ê¸°ì¡´ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if caption_path.exists() and not config.OVERWRITE_EXISTING:
        return 0

    # ë°±ì—… ìƒì„±
    if config.CREATE_BACKUP and caption_path.exists():
        create_backup(caption_path)

    # 1. BLIP ìº¡ì…˜ ìƒì„±
    # blip_caption = generate_blip_caption(
    #     image_path, blip_model, blip_processor, config
    # )
    blip_caption = generate_blip_caption(image_path)

    # 2. WD14 íƒœê·¸ ìƒì„±
    # wd14_tags = generate_wd14_tags(image_path, wd14_tagger, config)
    wd14_tags = generate_wd14_tags(image_path)

    # 3. ë³‘í•©
    merged_caption = merge_captions(blip_caption, wd14_tags)

    # 4. ìºë¦­í„°ëª… prefix ì¶”ê°€
    if config.CHARACTER_PREFIX:
        char_token = config.CHARACTER_PREFIX.strip()
        merged_caption = f"{char_token}, {merged_caption}"

    # 5. ì €ì¥
    if merged_caption:
        with open(caption_path, 'w', encoding=config.OUTPUT_ENCODING) as f:
            f.write(merged_caption)
        return 1
    else:
        print(f"âš ï¸ ë¹ˆ ìº¡ì…˜: {image_path.name}")


# ==============================
# ğŸ·ï¸ WD14 Tagger í´ë˜ìŠ¤
# ==============================
class WD14Tagger:

    def __init__(
            self,
            config,
            model_dir=None,
            repo_id=None,
            onnx=True,
            general_threshold=0.35,
            character_threshold=0.85,
            device=None,
    ):
        self.config = config
        self.model_dir = model_dir or config.WD14_CACHE_DIR
        self.repo_id = repo_id or config.WD14_MODEL_PATH
        self.onnx = onnx
        self.general_threshold = general_threshold
        self.character_threshold = character_threshold
        self.device = device

        # âœ… tag_freq ì´ˆê¸°í™”
        self.tag_freq = {}

        # ëª¨ë¸ ì´ˆê¸°í™”
        self._init_model()

    def _init_model(self):
        """ëª¨ë¸ ë¡œë”© ë° ë ˆì´ë¸” CSV ì²˜ë¦¬"""
        from huggingface_hub import hf_hub_download

        model_location = os.path.join(self.model_dir, self.repo_id.replace("/", "_"))
        os.makedirs(model_location, exist_ok=True)

        # ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        if self.onnx:
            onnx_path = os.path.join(model_location, "model.onnx")
            if not os.path.exists(onnx_path):
                print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/model.onnx")
                hf_hub_download(
                    repo_id=self.repo_id,
                    filename="model.onnx",
                    local_dir=model_location
                )

            model = onnx.load(onnx_path)
            self.input_name = model.graph.input[0].name
            del model

            # Provider ì„¤ì •
            providers = ["CPUExecutionProvider"]
            available_providers = ort.get_available_providers()
            if "CUDAExecutionProvider" in available_providers:
                providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
            elif "ROCMExecutionProvider" in available_providers:
                providers = ["ROCMExecutionProvider", "CPUExecutionProvider"]

            self.ort_sess = ort.InferenceSession(onnx_path, providers=providers)

        # CSV ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        csv_file = os.path.join(model_location, "selected_tags.csv")
        if not os.path.exists(csv_file):
            print(f"    ë‹¤ìš´ë¡œë“œ ì¤‘: {self.repo_id}/selected_tags.csv")
            hf_hub_download(
                repo_id=self.repo_id,
                filename="selected_tags.csv",
                local_dir=model_location
            )

        import csv
        with open(csv_file, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            lines = list(reader)

        header, rows = lines[0], lines[1:]
        assert header[0] == "tag_id" and header[1] == "name" and header[2] == "category"

        self.rating_tags = [row[1] for row in rows if row[2] == "9"]
        self.general_tags = [row[1] for row in rows if row[2] == "0"]
        self.character_tags = [row[1] for row in rows if row[2] == "4"]

    def tag(self, image_path, general_threshold=None, character_threshold=None):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ íƒœê¹… - íƒœê·¸ ë¬¸ìì—´ ë°˜í™˜
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            img = Image.open(image_path).convert("RGB")
            img_array = preprocess_image(img)
            img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

            # ì¶”ë¡ 
            preds = self.ort_sess.run(None, {self.input_name: img_array})[0]

            # Threshold ì„¤ì •
            gen_thresh = general_threshold if general_threshold is not None else self.general_threshold
            char_thresh = character_threshold if character_threshold is not None else self.character_threshold

            # íƒœê·¸ ì¶”ì¶œ
            tags = []

            # Character íƒœê·¸ ë¨¼ì € (ìˆìœ¼ë©´)
            for i, tag in enumerate(self.character_tags):
                if preds[0][i] >= char_thresh:
                    tags.append(tag.replace('_', ' '))

            # General íƒœê·¸
            for i, tag in enumerate(self.general_tags):
                if preds[0][len(self.character_tags) + i] >= gen_thresh:
                    tags.append(tag.replace('_', ' '))

            return ', '.join(tags)

        except Exception as e:
            print(f"âš ï¸ WD14 íƒœê¹… ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return ""
