#!/usr/bin/env python3
"""
SDXL LoRA ë‹¨ì¼ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ê³ ê¸‰ ì‚¬ìš©ììš©)
- íŠ¹ì • í´ë”ë§Œ ì„ íƒ í•™ìŠµ
- ì„¸ë°€í•œ íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥
- Config ì˜¤ë²„ë¼ì´ë“œ
"""

import os
import sys
import json
import toml
import subprocess
import argparse
from pathlib import Path


def get_vram_size(gpu_id=0):
    """NVIDIA GPU VRAM í¬ê¸° ê°ì§€ (GB)"""
    try:
        cmd = [
            "nvidia-smi",
            "--query-gpu=memory.total",
            "--format=csv,noheader,nounits",
            "-i", str(gpu_id)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        vram_mb = int(result.stdout.strip())
        return vram_mb // 1024
    except:
        return 24  # ê¸°ë³¸ê°’


def count_images(folder_path):
    """í´ë” ë‚´ ì´ë¯¸ì§€ ê°œìˆ˜ ì„¸ê¸°"""
    extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp'}
    count = 0
    for file in folder_path.iterdir():
        if file.suffix.lower() in extensions:
            count += 1
    return count


def calculate_auto_params(image_count, vram_size, batch_size=1):
    """ì´ë¯¸ì§€ ìˆ˜ ê¸°ë°˜ ìë™ íŒŒë¼ë¯¸í„° ê³„ì‚°"""
    target_steps = 1800 if vram_size >= 20 else 1500

    # Repeats ê³„ì‚°
    if image_count < 20:
        repeats = max(80, min(200, target_steps // (image_count * 10)))
    elif image_count < 50:
        repeats = max(30, min(80, target_steps // (image_count * 10)))
    elif image_count < 100:
        repeats = max(15, min(30, target_steps // (image_count * 10)))
    else:
        repeats = max(5, min(20, target_steps // (image_count * 10)))

    # Epochs ê³„ì‚°
    images_per_epoch = image_count * repeats
    steps_per_epoch = images_per_epoch // batch_size
    epochs = max(1, round(target_steps / steps_per_epoch))
    epochs = min(max(epochs, 5), 30)

    return {
        'repeats': repeats,
        'epochs': epochs,
        'steps_per_epoch': steps_per_epoch,
        'total_steps': epochs * steps_per_epoch
    }


def main():
    parser = argparse.ArgumentParser(
        description="SDXL LoRA ë‹¨ì¼ í•™ìŠµ (ê³ ê¸‰ ì„¤ì •)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ (ìë™ ê³„ì‚°)
  python train_single.py --folder ../dataset/training/01_alice

  # ìˆ˜ë™ íŒŒë¼ë¯¸í„° ì§€ì •
  python train_single.py --folder ../dataset/training/01_alice --epochs 20 --repeats 30

  # Learning rate ì¡°ì •
  python train_single.py --folder ../dataset/training/01_alice --lr 0.0002

  # Network dim ë³€ê²½
  python train_single.py --folder ../dataset/training/01_alice --dim 64 --alpha 32

  # ì´ì–´ì„œ í•™ìŠµ (Resume)
  python train_single.py --folder ../dataset/training/01_alice --resume ../output_models/alice-epoch-010.safetensors

  # Resume + íŒŒë¼ë¯¸í„° ë³€ê²½
  python train_single.py --folder ../dataset/training/01_alice --resume ../output_models/alice-epoch-010.safetensors --epochs 30 --lr 0.00008

  # ì „ì²´ ì»¤ìŠ¤í…€
  python train_single.py \\
    --folder ../dataset/training/01_alice \\
    --output alice_v2 \\
    --config config-24g.toml \\
    --gpu 0 \\
    --epochs 25 \\
    --repeats 40 \\
    --lr 0.00015 \\
    --dim 64 \\
    --alpha 32 \\
    --batch-size 2
        """
    )

    # í•„ìˆ˜ ì¸ì
    parser.add_argument(
        "--folder",
        required=True,
        help="í•™ìŠµí•  í´ë” ê²½ë¡œ (ì˜ˆ: ../dataset/training/01_alice)"
    )

    # ê¸°ë³¸ ì„¤ì •
    parser.add_argument(
        "--config",
        default="config-24g.toml",
        help="Config íŒŒì¼ (ê¸°ë³¸: config-24g.toml)"
    )

    parser.add_argument(
        "--output",
        help="ì¶œë ¥ LoRA ì´ë¦„ (ê¸°ë³¸: í´ë”ëª…ì—ì„œ ì¶”ì¶œ)"
    )

    parser.add_argument(
        "--gpu",
        type=int,
        default=0,
        help="GPU ID (ê¸°ë³¸: 0)"
    )

    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    parser.add_argument(
        "--epochs",
        type=int,
        help="ì´ Epoch ìˆ˜ (ê¸°ë³¸: ìë™ ê³„ì‚°)"
    )

    parser.add_argument(
        "--repeats",
        type=int,
        help="ì´ë¯¸ì§€ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸: ìë™ ê³„ì‚°)"
    )

    parser.add_argument(
        "--batch-size",
        type=int,
        help="ë°°ì¹˜ ì‚¬ì´ì¦ˆ (ê¸°ë³¸: config ê°’)"
    )

    parser.add_argument(
        "--lr",
        type=float,
        help="Learning rate (ê¸°ë³¸: config ê°’, ë³´í†µ 1e-4)"
    )

    parser.add_argument(
        "--dim",
        type=int,
        help="Network dimension (ê¸°ë³¸: config ê°’, ë³´í†µ 32)"
    )

    parser.add_argument(
        "--alpha",
        type=int,
        help="Network alpha (ê¸°ë³¸: config ê°’, ë³´í†µ 16)"
    )

    parser.add_argument(
        "--resolution",
        help="í•´ìƒë„ (ì˜ˆ: 1024,1024 ë˜ëŠ” 768,768)"
    )

    parser.add_argument(
        "--save-every",
        type=int,
        help="N epochë§ˆë‹¤ ì €ì¥ (ê¸°ë³¸: config ê°’)"
    )

    # ê³ ê¸‰ ì˜µì…˜
    parser.add_argument(
        "--optimizer",
        help="Optimizer (ì˜ˆ: AdamW8bit, Lion, Prodigy)"
    )

    parser.add_argument(
        "--scheduler",
        help="LR Scheduler (ì˜ˆ: cosine, constant, polynomial)"
    )

    parser.add_argument(
        "--no-auto",
        action="store_true",
        help="ìë™ ê³„ì‚° ë¹„í™œì„±í™” (epochs/repeats ìˆ˜ë™ ì§€ì • í•„ìˆ˜)"
    )

    # Resume ì˜µì…˜
    parser.add_argument(
        "--resume",
        help="ì´ì–´ì„œ í•™ìŠµí•  LoRA íŒŒì¼ ê²½ë¡œ (ì˜ˆ: ../output_models/alice-epoch-010.safetensors)"
    )

    args = parser.parse_args()

    # í´ë” í™•ì¸
    folder_path = Path(args.folder)
    if not folder_path.exists() or not folder_path.is_dir():
        print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        sys.exit(1)

    # ì´ë¯¸ì§€ ê°œìˆ˜
    image_count = count_images(folder_path)
    if image_count == 0:
        print(f"âŒ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        sys.exit(1)

    # VRAM ê°ì§€
    vram_size = get_vram_size(args.gpu)

    # Config ìë™ ì„ íƒ
    if vram_size >= 20:
        precision = "bf16"
        config_file = args.config if args.config else "config-24g.toml"
    else:
        precision = "fp16"
        config_file = args.config if args.config else "config-16g.toml"
        print(f"âš ï¸ VRAM {vram_size}GB < 20GB, fp16 ëª¨ë“œë¡œ ì „í™˜")

    # Config ë¡œë“œ
    if not os.path.exists(config_file):
        print(f"âŒ Config íŒŒì¼ ì—†ìŒ: {config_file}")
        sys.exit(1)

    with open(config_file, 'r', encoding='utf-8') as f:
        config = toml.load(f)

    batch_size = args.batch_size or config['training'].get('batch_size', 1)

    # ì¶œë ¥ ì´ë¦„ ê²°ì •
    if args.output:
        output_name = args.output
    else:
        # í´ë”ëª…ì—ì„œ ì¶”ì¶œ (01_alice â†’ alice)
        folder_name = folder_path.name
        parts = folder_name.split('_', 1)
        if len(parts) == 2 and parts[0].isdigit():
            output_name = parts[1]
        else:
            output_name = folder_name

    # íŒŒë¼ë¯¸í„° ê²°ì •
    if args.no_auto:
        # ìˆ˜ë™ ëª¨ë“œ
        if not args.epochs or not args.repeats:
            print("âŒ --no-auto ì‚¬ìš© ì‹œ --epochsì™€ --repeats í•„ìˆ˜ì…ë‹ˆë‹¤")
            sys.exit(1)
        epochs = args.epochs
        repeats = args.repeats
        steps_per_epoch = (image_count * repeats) // batch_size
        total_steps = epochs * steps_per_epoch
    else:
        # ìë™ ê³„ì‚° (ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
        auto_params = calculate_auto_params(image_count, vram_size, batch_size)
        epochs = args.epochs or auto_params['epochs']
        repeats = args.repeats or auto_params['repeats']
        steps_per_epoch = (image_count * repeats) // batch_size
        total_steps = epochs * steps_per_epoch

    # í•™ìŠµ ì •ë³´ ì¶œë ¥
    print(f"\n{'=' * 70}")
    print(f"ğŸ¯ SDXL LoRA Training - Single Mode")
    print(f"{'=' * 70}")
    print(f"ğŸ“ Folder:         {folder_path}")
    print(f"ğŸ’¾ Output:         {output_name}.safetensors")
    print(f"ğŸ“‹ Config:         {config_file}")
    print(f"ğŸ–¥ï¸  GPU:            {args.gpu} ({vram_size}GB VRAM)")
    print(f"âš¡ Precision:      {precision}")

    # Resume ì •ë³´
    if args.resume:
        if not os.path.exists(args.resume):
            print(f"âŒ Resume íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.resume}")
            sys.exit(1)
        print(f"ğŸ”„ Resume from:    {args.resume}")

    print(f"{'-' * 70}")
    print(f"ğŸ“Š Training Parameters")
    print(f"{'-' * 70}")
    print(f"  Images:          {image_count}")
    print(f"  Repeats:         {repeats}" + (" (manual)" if args.repeats else " (auto)"))
    print(f"  Epochs:          {epochs}" + (" (manual)" if args.epochs else " (auto)"))
    print(f"  Batch size:      {batch_size}" + (" (override)" if args.batch_size else ""))
    print(f"  Images/epoch:    {image_count * repeats}")
    print(f"  Steps/epoch:     {steps_per_epoch}")
    print(f"  Total steps:     {total_steps}")

    # ì˜¤ë²„ë¼ì´ë“œëœ íŒŒë¼ë¯¸í„° í‘œì‹œ
    overrides = []
    if args.lr:
        print(f"  Learning rate:   {args.lr} (override)")
        overrides.append(('lr', args.lr))
    if args.dim:
        print(f"  Network dim:     {args.dim} (override)")
        overrides.append(('dim', args.dim))
    if args.alpha:
        print(f"  Network alpha:   {args.alpha} (override)")
        overrides.append(('alpha', args.alpha))
    if args.resolution:
        print(f"  Resolution:      {args.resolution} (override)")
        overrides.append(('resolution', args.resolution))
    if args.optimizer:
        print(f"  Optimizer:       {args.optimizer} (override)")
        overrides.append(('optimizer', args.optimizer))
    if args.scheduler:
        print(f"  LR Scheduler:    {args.scheduler} (override)")
        overrides.append(('scheduler', args.scheduler))
    if args.save_every:
        print(f"  Save every:      {args.save_every} epochs (override)")
        overrides.append(('save_every', args.save_every))

    print(f"{'=' * 70}\n")

    # ì‚¬ìš©ì í™•ì¸
    try:
        response = input("í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() not in ['y', 'yes']:
            print("âŒ í•™ìŠµ ì·¨ì†Œë¨")
            sys.exit(0)
    except KeyboardInterrupt:
        print("\nâŒ í•™ìŠµ ì·¨ì†Œë¨")
        sys.exit(0)

    # accelerate ëª…ë ¹ì–´ êµ¬ì„±
    cmd = [
        "accelerate", "launch",
        "--num_cpu_threads_per_process", "1",
        "--mixed_precision", precision,
        "sdxl_train_network.py",
        f"--config_file={config_file}",
        f"--train_data_dir={folder_path}",
        f"--output_name={output_name}",
        f"--max_train_epochs={epochs}",
        f"--dataset_repeats={repeats}"
    ]

    # resume(ì´ì–´ë°›ê¸°) ì²˜ë¦¬ â€” ì•ˆì „í•˜ê²Œ
    # ëŒ€ë¶€ë¶„ì˜ ê²½ìš° users want to load model weights -> use --network_weights
    # Only use --resume if you have an accelerator checkpoint (full state)
    # resume ê°’ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì¼ ë•Œë§Œ ì „ë‹¬
    if args.resume:
        if os.path.exists(args.resume):
            # ëŒ€ë¶€ë¶„ì˜ ê²½ìš° model weights ë¡œë“œê°€ ëª©ì ì´ë¼ë©´ network_weightsë¡œ ì „ë‹¬
            cmd.append(f"--network_weights={str(args.resume)}")
            print(f"\nğŸ”„ Resuming weights from: {args.resume}\n")
        else:
            print(f"âŒ Resume íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.resume}")
            sys.exit(1)

    # ì˜¤ë²„ë¼ì´ë“œ ì¶”ê°€
    if args.batch_size:
        cmd.append(f"--train_batch_size={args.batch_size}")
    if args.lr:
        cmd.append(f"--learning_rate={args.lr}")
    if args.dim:
        cmd.append(f"--network_dim={args.dim}")
    if args.alpha:
        cmd.append(f"--network_alpha={args.alpha}")
    if args.resolution:
        cmd.append(f"--resolution={args.resolution}")
    if args.optimizer:
        cmd.append(f"--optimizer_type={args.optimizer}")
    if args.scheduler:
        cmd.append(f"--lr_scheduler={args.scheduler}")
    if args.save_every:
        cmd.append(f"--save_every_n_epochs={args.save_every}")

    # Resume ì¶”ê°€
    if args.resume:
        cmd.append(f"--network_weights={args.resume}")
        print(f"\nğŸ”„ Resuming from: {args.resume}\n")

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    env = os.environ.copy()
    env['CUDA_VISIBLE_DEVICES'] = str(args.gpu)

    # ì‹¤í–‰
    try:
        print(f"\nğŸš€ Starting training...\n")
        subprocess.run(cmd, env=env, check=True)
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ: {output_name}.safetensors")
        print(f"{'=' * 70}\n")

    except subprocess.CalledProcessError as e:
        print(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nâš ï¸ í•™ìŠµ ì¤‘ë‹¨ë¨")
        sys.exit(1)


if __name__ == "__main__":
    main()